{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d620a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Parth Sinha\n",
    "\"\"\"\n",
    "\n",
    "#------------------Import the required Packages-------------------------------------------------------------------------\n",
    "pip install tensorflow==1.1\n",
    "import sys\n",
    "sys.path.insert(0, '../../Utilities/')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    \"\"\"\n",
    "    t_star: time in hours (numpy array)\n",
    "    pH_star: PH of the culture (numpy array)\n",
    "    O2_star: Oxygen concentration in the bioreactor (numpy array)\n",
    "    CO2_star: Carbon dioxide concentration in the bioreactor (numpy array)\n",
    "    feed_star: Feed added on specified days in Bioreactor (numpy array)\n",
    "    X_star: Cell/Biomass concentration in the bioreactor (numpy array)\n",
    "    S1_star: Glucose concentration in the bioreactor (numpy array)\n",
    "    S2_star: Glutamine concentration in the bioreactor (numpy array)\n",
    "    S3_star: Glutamate concentration in the bioreactor (numpy array)\n",
    "    S4_star: Lactate concentration in the bioreactor (numpy array)\n",
    "    S5_star: Ammonia concentration in the bioreactor (numpy array)\n",
    "    s6_star: Titer concentration in the bioreactor (numpy array)\n",
    "    Layers: List of neurons in the input, hidden and output layers\n",
    "    lb: Lower bound of the Input to the ANN\n",
    "    ub: Upper bound of the Input to the ANN\n",
    "    \"\"\"\n",
    "    def __init__(self, t_star, pH_star, O2_star, CO2_star, feed_star, X_star, S1_star, S2_star, S3_star, S4_star, S5_star, S6_star, layers, lb, ub):\n",
    "        \n",
    "\n",
    "        self.t = np.reshape(t_star, (-1,1))                           # Converting the row to column\n",
    "        self.pH = pH_star\n",
    "        self.O2 = O2_star\n",
    "        self.CO2 = CO2_star\n",
    "        self.feed = feed_star\n",
    "        self.x = X_star\n",
    "        self.s1 = S1_star\n",
    "        self.s2 = S2_star\n",
    "        self.s3 = S3_star\n",
    "        self.s4 = S4_star\n",
    "        self.s5 = S5_star\n",
    "        self.s6 = S6_star\n",
    "        # self.code = code\n",
    "\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "\n",
    "\n",
    "        # Initialize NN\n",
    "        self.layers = layers\n",
    "        self.weights, self.biases = self.initialize_NN(layers)      # Initializing the weights and bias with some initial guess\n",
    "\n",
    "        print(self.weights)\n",
    "\n",
    "        # Paper 2\n",
    "        \"\"\" Initial guess for the unknown parameters \"\"\"\n",
    "        \"\"\" Variables keeps on changing with iterations \n",
    "        , constraint=lambda t: tf.clip_by_value(t, 0, np.inf)\"\"\"\n",
    "        self.mu_m = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))            # Maximum growth rate of the cell culture\n",
    "        self.kd_m = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))            # Maximum death rate of the cell culture\n",
    "\n",
    "        self.k1 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))              # Monod constant for glucose\n",
    "        self.k2 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))              # Monod constant for glutamine\n",
    "        self.k3 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))              # Monod constant for glutamate\n",
    "        self.k4 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))              # Monod constant for Lactate\n",
    "        self.k5 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))              # Monod constant for Ammonia\n",
    "\n",
    "        self.Y_xs1 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))           # Yield factor Cells/glucose\n",
    "        self.Y_xs2 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))           # Yield factor Cells/glutamine\n",
    "        self.Y_xs3 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))           # Yield factor Cells/glutamate\n",
    "        self.Y_xs5 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))           # Yield factor Cells/ammonia\n",
    "        self.Y_xs6 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))          # Yield factor Cells/Titer\n",
    "        self.Y_s2s3 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))          # Yield factor glutamine/glutamate\n",
    "        self.Y_s1s4 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))          # Yield factor glucose/lactate\n",
    "        self.ms1 = tf.Variable([1.0], dtype=tf.float32, constraint=lambda t: tf.clip_by_value(t, 0, np.inf))             # Maintenance constant for glucose\n",
    "\n",
    "\n",
    "        # tf placeholders and graph\n",
    "        self.sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True,\n",
    "                                                                         log_device_placement=True))\n",
    "\n",
    "        \"\"\"\n",
    "        Placeholders are used to feed data later when needed in the ANN graphs\n",
    "        \"\"\"\n",
    "        self.t_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.t.shape[1]], name='t_tf')\n",
    "        self.pH_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.pH.shape[1]], name='pH_tf')\n",
    "        self.O2_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.O2.shape[1]], name='O2_tf')\n",
    "        self.CO2_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.CO2.shape[1]], name='CO2_tf')\n",
    "        self.feed_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.feed.shape[1]], name='feed_tf')\n",
    "\n",
    "        self.x_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
    "        self.s1_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.s1.shape[1]])\n",
    "        self.s2_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.s2.shape[1]])\n",
    "        self.s3_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.s3.shape[1]])\n",
    "        self.s4_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.s4.shape[1]])\n",
    "        self.s5_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.s5.shape[1]])\n",
    "        self.s6_tf = tf.compat.v1.placeholder(tf.float32, shape=[None, self.s6.shape[1]])\n",
    "\n",
    "        # tf graphs\n",
    "        \"\"\"\n",
    "        x_pred: Predicted Biomass/Cell viability\n",
    "        s1_pred: Predicted Glucose concentration\n",
    "        s2_pred: Predicted Glutamine concentration\n",
    "        s3_pred: Predicted Glutamate concentration\n",
    "        s4_pred: Predicted Lactate concentration\n",
    "        s5_pred: Predicted Ammonia concentration\n",
    "        s6_pred: Predicted Titer concentration        \n",
    "        f_pred: Mass balance error for cell culture\n",
    "        f_s1_pred: Mass Balance error for glucose\n",
    "        f_s2_pred: Mass Balance error for glutamine\n",
    "        f_s3_pred: Mass Balance error for glutamate\n",
    "        f_s4_pred: Mass Balance error for Lactate\n",
    "        f_s5_pred: Mass Balance error for Ammonia\n",
    "        net_f_uv: Function for predicting the Bioreactors profile\n",
    "        \"\"\"\n",
    "        self.x_pred, self.s1_pred, self.s2_pred, self.s3_pred, self.s4_pred, self.s5_pred, self.s6_pred, \\\n",
    "        self.f_pred, self.f_s1_pred, self.f_s2_pred, self.f_s3_pred, self.f_s4_pred, self.f_s5_pred, self.f_s6_pred = \\\n",
    "                                                        self.net_f_uv(self.t_tf, self.pH_tf, self.O2_tf, self.CO2_tf, self.feed_tf)\n",
    "\n",
    "        \"\"\"\n",
    "        Define the loss function: (predicted - actual) for all the components\n",
    "        Loss = sum(predicted-actual) + sum(f_xx_pred - 0)\n",
    "        \"\"\"\n",
    "        self.loss = tf.compat.v1.reduce_sum(tf.square(self.x_tf - self.x_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.s1_tf - self.s1_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.s2_tf - self.s2_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.s3_tf - self.s3_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.s4_tf - self.s4_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.s5_tf - self.s5_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.s6_tf - self.s6_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.f_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.f_s1_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.f_s2_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.f_s3_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.f_s4_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.f_s5_pred)) + \\\n",
    "                    tf.compat.v1.reduce_sum(tf.square(self.f_s6_pred))\n",
    "\n",
    "        # Adding L1-regularization on the weights\n",
    "        self.l1_regularizer = tf.contrib.layers.l1_regularizer(scale=0.005, scope=None)\n",
    "        self.regularization_penalty = tf.contrib.layers.apply_regularization(self.l1_regularizer, self.weights)\n",
    "        self.regularized_loss = self.loss + self.regularization_penalty\n",
    "\n",
    "        # self.l1_regularizer = tf.keras.regularizers.L1(l1=0.01)\n",
    "\n",
    "        \"\"\"Define the settings for the optimizer once the training is done\"\"\"\n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.regularized_loss,\n",
    "                                                                method = 'L-BFGS-B',\n",
    "                                                                options = {'maxiter': 500000,\n",
    "                                                                           'maxfun': 500000,\n",
    "                                                                           'maxcor': 5000,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol': 1.0 * np.finfo(float).eps})\n",
    "\n",
    "        \"\"\"\n",
    "        Define the settings for the optimizer for back-propogation for tuning the unknown parameters, weights and Bias\n",
    "        \"\"\"\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer() #learning_rate=0.001\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.regularized_loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_NN(self, layers):                                                            # Initialize the ANN weights and Bias\n",
    "        weights = []                                                                            # Initialize the empty weights and Bias\n",
    "        biases = []\n",
    "        num_layers = len(layers)                                                                # Total number of layers\n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.wb_init(size=[layers[l], layers[l+1]])                                     # Generate the weights of each pair of consecutive layers\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)      # Initialize the bias with 0s\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def wb_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        stddev = np.sqrt(2/(in_dim + out_dim))                                                  # Initialize the weights with sqrt(2/(in_dim+out_dim))\n",
    "        return tf.Variable(tf.random.truncated_normal([in_dim, out_dim], stddev=stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):                                                   # Predict the Output\n",
    "        num_layers = len(weights) + 1\n",
    "\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0                                         # Scale the Input array\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))                                             # Use tanh activation fucntion to predict the parameters for every next layer\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b, name='output')                                           # Predict the final output layer parameters\n",
    "        return Y\n",
    "\n",
    "    def net_f_uv(self, t, pH, O2, CO2, feed):                                                          # Considers the 1st principle model as a constraint\n",
    "\n",
    "        mu_m = self.mu_m                    # Maximum cell growth rate\n",
    "        kd_m = self.kd_m                    # Maximum cell death rate\n",
    "        k1 = self.k1                        # Monod constant for glucose\n",
    "        k2 = self.k2                        # Monod constant for glutamine\n",
    "        k3 = self.k3                        # Monod constant for glutamate\n",
    "        k4 = self.k4                        # Monod constant for Lactate\n",
    "        k5 = self.k5                        # Monod constant for Ammonia\n",
    "        Y_xs1 = self.Y_xs1                  # Yield factor cells/glucose\n",
    "        Y_xs2 = self.Y_xs2                  # Yield factor cells/glutamine\n",
    "        Y_xs3 = self.Y_xs3                  # Yield factor cells/glutamate\n",
    "        Y_xs5 = self.Y_xs5                  # Yield factor cells/ammonia\n",
    "        Y_xs6 = self.Y_xs6                  # Yield factor cells/titer\n",
    "        Y_s2s3 = self.Y_s2s3                # Yield factor glutamine/glutamate\n",
    "        Y_s1s4 = self.Y_s1s4                # Yield factor glucose/lactate\n",
    "        ms1 = self.ms1                      # Maintenance constant for glucose\n",
    "\n",
    "        T = self.neural_net(tf.concat([t,pH,O2,CO2,feed], 1), self.weights, self.biases)     # Predicts the Bioreactor parameters\n",
    "        x = T[:,0:1]                        # Predicted Biomass/Cell Viability\n",
    "        s1 = T[:,1:2]                       # Predicted Glucose\n",
    "        s2 = T[:,2:3]                       # Predicted Glutamine\n",
    "        s3 = T[:,3:4]                       # Predicted Glutamate\n",
    "        s4 = T[:,4:5]                       # Predicted Lactate\n",
    "        s5 = T[:,5:6]                       # Predicted Ammonia\n",
    "        s6 = T[:,6:7]                       # Predicted Titer\n",
    "\n",
    "\n",
    "        x_t = tf.gradients(x, t)[0]         # First order derivative of Biomass\n",
    "        s1_t = tf.gradients(s1, t)[0]       # First order derivative of Glucose\n",
    "        s2_t = tf.gradients(s2, t)[0]       # First order derivative of Glutamine\n",
    "        s3_t = tf.gradients(s3, t)[0]       # First order derivative of Glutamate\n",
    "        s4_t = tf.gradients(s4, t)[0]       # First order derivative of Lactate\n",
    "        s5_t = tf.gradients(s5, t)[0]       # First order derivative of Ammonia\n",
    "        s6_t = tf.gradients(s6, t)[0]       # First order derivative of titer\n",
    "\n",
    "        \"\"\"\n",
    "        Solving the rate kinetics using the ANN predictions (Components predicted by ANN)\n",
    "        \"\"\"\n",
    "\n",
    "        # # Paper 1 : https://www.mdpi.com/2227-9717/7/3/166/htm\n",
    "\n",
    "        # mu = mu_m * (s1/(k1+s1)) * (s2/(k2+s2)) * (k3/(k3+s3)) * (k4/(k4+s4))\n",
    "        # mu_d = kd * (s3/(kd_3+s3)) * (s4/(kd_4+s4))\n",
    "\n",
    "        # f_x = x_t - ((mu-mu_d) * x) # Biomass balance\n",
    "        # f_s1 = s1_t + ((((mu-mu_d)/Y_xs1) + ms1) * x) # Glucose Balance\n",
    "        # f_s3 = s3_t - (Y_s3s1 * ((mu-mu_d)/Y_xs1) * x) #\n",
    "        # f_s2 = s2_t + ((((mu-mu_d)/Y_xs2) + ms2) * x) #\n",
    "        # f_s4 = s4_t - (Y_s4s2 * ((mu-mu_d)/Y_xs2) * x) + (ramm * x)\n",
    "        # # f_p = P_t - (Q * x)\n",
    "\n",
    "\n",
    "        # Paper 2 : https://www.americanpharmaceuticalreview.com/Featured-Articles/517739-Hybrid-Model-Identification-for-Monoclonal-Antibody-Production-Bioreactor-A-Digital-Twin/\n",
    "\n",
    "        mu = mu_m * (s1/(k1+s1)) #* (s2/(k2+s2)) * (k4/(k4+s4)) * (k5/(k5+s5))       # Monod Kinetics for cell Growth\n",
    "        kd = kd_m * (s5/(k5+s5))                                    # Monod Kinetics for cell death\n",
    "\n",
    "        f_x = x_t - ((mu-kd) * x)                                   # Biomass balance\n",
    "        f_s1 = s1_t + (((mu/Y_xs1) + ms1) * x)                      # Glucose Balance\n",
    "        f_s2 = s2_t + ((1/Y_xs2) * (s2/(k2+s2)) * x)                # Glutamine Balance\n",
    "        f_s3 = s3_t + ((1/Y_xs3) * (s3/(k3+s3)) * x) - (s2/Y_s2s3)  # Glutamate Balance\n",
    "        # f_s4 = s4_t - ((1/(Y_s1s4)) * mu * s1)                    # Lactate Balance Balance - Referenced from paper 2\n",
    "        f_s4 = s4_t - (Y_s1s4 * ((mu-kd)/Y_xs1) * x)                # Lactate Balance - Referenced from paper 1\n",
    "        f_s5 = s5_t - ((1/Y_xs5) * (s3/(k3+s3)) * x)                # Ammonia Balance\n",
    "        f_s6 = s6_t - ((1/Y_xs6) * mu * x)                          # Titer Balance\n",
    "\n",
    "        # mu_m, kd_m, Y_xs1, ms1, Y_xs2, k2, Y_xs3, k3, Y_s2s3, Y_s1s4, Y_xs5, k1, k5\n",
    "\n",
    "        return x, s1, s2, s3, s4, s5, s6, f_x, f_s1, f_s2, f_s3, f_s4, f_s5, f_s6\n",
    "    \n",
    "    def callback(self, loss, mu_m, kd_m, k1, k2, k3, k4, k5, Y_xs1,  Y_xs2, Y_xs3, Y_xs5, Y_xs6, Y_s2s3, Y_s1s4, ms1):\n",
    "\n",
    "        print('Loss: %.3e, mu_m: %.8f, kd_m: %.8f, k1: %.8f, k2: %.8f, k3: %.8f, k4: %.8f, k5: %.8f, Y_xs1: %.8f, \\\n",
    "               Y_xs2: %.8f, Y_xs3: %.8f, Y_xs5: %.8f, Y_xs6: %.8f, Y_s2s3: %.8f, Y_s1s4: %.8f, ms1: %.8f' \\\n",
    "              % (loss, mu_m, kd_m, k1, k2, k3, k4, k5, Y_xs1,  Y_xs2, Y_xs3, Y_xs5, Y_xs6, Y_s2s3, Y_s1s4, ms1))\n",
    "      \n",
    "    def train(self, nIter): # Train using the Training dataset\n",
    "        # Create a dictionary of all the input and output arrays which will go for training purpose\n",
    "        tf_dict = {self.t_tf: self.t,\n",
    "                   self.pH_tf: self.pH,\n",
    "                   self.O2_tf: self.O2,\n",
    "                   self.CO2_tf: self.CO2,\n",
    "                   self.feed_tf: self.feed,\n",
    "                   self.x_tf: self.x,\n",
    "                   self.s1_tf: self.s1,\n",
    "                   self.s2_tf: self.s2,\n",
    "                   self.s3_tf: self.s3,\n",
    "                   self.s4_tf: self.s4,\n",
    "                   self.s5_tf: self.s5,\n",
    "                   self.s6_tf: self.s6}\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)                          # Run the adam optimizer using the input dictionary\n",
    "            \n",
    "            # Print\n",
    "            if it % 100 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                loss_value = self.sess.run(self.regularized_loss, tf_dict)      # Computes the loss after every 100 iterations\n",
    "                ## After every 100 iterations compute the values of the unknown parameters\n",
    "                mu_m_value = self.sess.run(self.mu_m)\n",
    "                kd_m_value = self.sess.run(self.kd_m)\n",
    "                k1_value = self.sess.run(self.k1)\n",
    "                k2_value = self.sess.run(self.k2)\n",
    "                k3_value = self.sess.run(self.k3)\n",
    "                k4_value = self.sess.run(self.k4)\n",
    "                k5_value = self.sess.run(self.k5)\n",
    "                Y_xs1_value = self.sess.run(self.Y_xs1)\n",
    "                Y_xs2_value = self.sess.run(self.Y_xs2)\n",
    "                Y_xs3_value = self.sess.run(self.Y_xs3)\n",
    "                Y_xs5_value = self.sess.run(self.Y_xs5)\n",
    "                Y_xs6_value = self.sess.run(self.Y_xs6)\n",
    "                Y_s2s3_value = self.sess.run(self.Y_s2s3)\n",
    "                Y_s1s4_value = self.sess.run(self.Y_s1s4)\n",
    "                ms1_value = self.sess.run(self.ms1)\n",
    "\n",
    "\n",
    "                print('It: %d, Loss: %.3e, mu_m: %.8f, kd_m: %.8f, k1: %.8f, k2: %.8f, k3: %.8f, k4: %.8f, k5: %.8f, Y_xs1: %.8f,  \\\n",
    "                       Y_xs2: %.8f, Y_xs3: %.8f, Y_xs5: %.8f, Y_xs6: %.8f, Y_s2s3: %.8f, Y_s1s4: %.8f, ms1: %.8f, Time: %.2f' \\\n",
    "                      % (it, loss_value, mu_m_value, kd_m_value, k1_value, k2_value, k3_value, k4_value, k5_value, \\\n",
    "                         Y_xs1_value, Y_xs2_value, Y_xs3_value, Y_xs5_value, Y_xs6_value, Y_s2s3_value, Y_s1s4_value, ms1_value, elapsed))\n",
    "\n",
    "                start_time = time.time()\n",
    "            \n",
    "        self.optimizer.minimize(self.sess,\n",
    "                                feed_dict = tf_dict,\n",
    "                                fetches = [self.regularized_loss, self.mu_m, self.kd_m, self.k1, self.k2, self.k3, self.k4, self.k5,\\\n",
    "                                           self.Y_xs1, self.Y_xs2, self.Y_xs3, self.Y_xs5, self.Y_xs6, self.Y_s2s3, self.Y_s1s4, self.ms1],\n",
    "                                loss_callback = self.callback)\n",
    "\n",
    "    \n",
    "    def predict(self, t_star, pH_star, O2_star, CO2_star, feed_star):  # Predict using the testing dataset\n",
    "        \n",
    "        tf_dict = {self.t_tf: t_star,\n",
    "                   self.pH_tf: pH_star,\n",
    "                   self.O2_tf: O2_star,\n",
    "                   self.CO2_tf: CO2_star,\n",
    "                   self.feed_tf: feed_star}\n",
    "        \n",
    "        x_star = self.sess.run(self.x_pred, tf_dict)\n",
    "        s1_star = self.sess.run(self.s1_pred, tf_dict)\n",
    "        s2_star = self.sess.run(self.s2_pred, tf_dict)\n",
    "        s3_star = self.sess.run(self.s3_pred, tf_dict)\n",
    "        s4_star = self.sess.run(self.s4_pred, tf_dict)\n",
    "        s5_star = self.sess.run(self.s5_pred, tf_dict)\n",
    "        s6_star = self.sess.run(self.s6_pred, tf_dict)\n",
    "        return x_star, s1_star, s2_star, s3_star, s4_star, s5_star, s6_star\n",
    "\n",
    "    def save_model(self):\n",
    "        # add save/restore ops\n",
    "        saver = tf.train.Saver()\n",
    "        # save after training\n",
    "        save_path = saver.save(self.sess, './model/Enbrel/Enbrel_model')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Domain Bounds (Lower and Upper) for the Input neurons for - time, pH, O2, CO2, Feed Addition\n",
    "    lb = np.array([0, 0, 0, 0, 0])\n",
    "    ub = np.array([270, 14, 140, 140, 50])\n",
    "\n",
    "    # Number of neurons for each layer in the neural network\n",
    "    # We have considered 5 hidden layers with 10 neurons in each\n",
    "    layers = [5, 10, 10, 10, 10, 10, 7]\n",
    "\n",
    "    # Load training Data\n",
    "    data = pd.read_csv('C:/Users/adarsh.sambare/OneDrive - Tridiagonal Solutions/TSPL/Pfizer/Soma 2 G new data/Soma_2G_Train.csv')\n",
    "    data.dropna(inplace=True)\n",
    "    col = data.columns\n",
    "\n",
    "    t_star = np.array(data[col[0:1]])       # Time\n",
    "    pH_star = np.array(data[col[1:2]])      # PH\n",
    "    O2_star = np.array(data[col[2:3]])      # Oxygen\n",
    "    CO2_star = np.array(data[col[3:4]])    # Carbon dioxide\n",
    "    feed_star = np.array(data[col[4:5]])     # Feed Addition in bioreactor\n",
    "    X_star = np.array(data[col[5:6]])       # Biomass/cell viable density\n",
    "    S1_star = np.array(data[col[6:7]])      # Glucose\n",
    "    S2_star = np.array(data[col[7:8]])      # Glutamine\n",
    "    S3_star = np.array(data[col[8:9]])      # Glutamate\n",
    "    S4_star = np.array(data[col[9:10]])      # Lactate\n",
    "    S5_star = np.array(data[col[10:11]])      # Ammonia\n",
    "    S6_star = np.array(data[col[11:12]])      # Titer\n",
    "    # code_star = np.array(data[col[12:13]])    # Batch Code\n",
    "\n",
    "# ----------------- TRAINING THE ARTIFICIAL NEURAL NETWORK -------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    For the current Architecture time, pH, Oxygen, Carbon Dioxide are the inputs\n",
    "    Biomass, Glucose, Glutamine, Glutamate, Lactate, Ammonia are the outputs\n",
    "    \"\"\"\n",
    "\n",
    "    model = PhysicsInformedNN(t_star, pH_star, O2_star, CO2_star, feed_star, X_star, S1_star, S2_star, S3_star, S4_star, S5_star, S6_star, layers, lb, ub)\n",
    "\n",
    "    # PhysicsInformedNN: Class for computing the physics constrained ANN\n",
    "    model.train(2000000)    # Train the ANN model for 2000000 iterations\n",
    "    model.save_model()\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "    # Prediction\n",
    "    # Test Data - Bench Scale\n",
    "    test_data = pd.read_csv('C:/Users/adarsh.sambare/OneDrive - Tridiagonal Solutions/TSPL/Pfizer/Soma 2 G new data/Soma_2G_Test.csv')\n",
    "    test_data.dropna(inplace=True)\n",
    "    col = test_data.columns\n",
    "\n",
    "    t_star = np.array(test_data[col[0:1]])       # Time\n",
    "    pH_star = np.array(test_data[col[1:2]])      # PH\n",
    "    O2_star = np.array(test_data[col[2:3]])      # Oxygen\n",
    "    CO2_star = np.array(test_data[col[3:4]])    # Carbon dioxide\n",
    "    feed_star = np.array(test_data[col[4:5]])     # Feed addition\n",
    "    X_star = np.array(test_data[col[5:6]])       # Biomass/cell viable density\n",
    "    S1_star = np.array(test_data[col[6:7]])      # Glucose\n",
    "    S2_star = np.array(test_data[col[7:8]])      # Glutamine\n",
    "    S3_star = np.array(test_data[col[8:9]])      # Glutamate\n",
    "    S4_star = np.array(test_data[col[9:10]])      # Lactate\n",
    "    S5_star = np.array(test_data[col[10:11]])      # Ammonia\n",
    "    S6_star = np.array(test_data[col[11:12]])      # Titer\n",
    "\n",
    "    # Prediction\n",
    "    x_pred, s1_pred, s2_pred, s3_pred, s4_pred, s5_pred, s6_pred = model.predict(t_star, pH_star, O2_star, CO2_star, feed_star)\n",
    "\n",
    "    df_pred = pd.DataFrame({'pH': pH_star.reshape(-1),\n",
    "                            'O2': O2_star.reshape(-1),\n",
    "                            'CO2': CO2_star.reshape(-1),\n",
    "                            'Feed': feed_star.reshape(-1),\n",
    "                            'Biomass': x_pred.reshape(-1),\n",
    "                            'Glucose': s1_pred.reshape(-1),\n",
    "                            'Glutamine': s2_pred.reshape(-1),\n",
    "                            'Glutamate': s3_pred.reshape(-1),\n",
    "                            'Lactate': s4_pred.reshape(-1),\n",
    "                            'Ammonia': s5_pred.reshape(-1),\n",
    "                            'Titer': s6_pred.reshape(-1),}, index = t_star.reshape(-1))\n",
    "\n",
    "    df_pred.to_csv('../data/bioreactors/Enbrel/pred-bench_pilot.csv')\n",
    "    # Error\n",
    "    error_x = np.linalg.norm(X_star - x_pred, 2) / np.linalg.norm(X_star, 2)\n",
    "    error_s1 = np.linalg.norm(S1_star - s1_pred, 2) / np.linalg.norm(S1_star, 2)\n",
    "    error_s2 = np.linalg.norm(S2_star - s2_pred, 2) / np.linalg.norm(S2_star, 2)\n",
    "    error_s3 = np.linalg.norm(S3_star - s3_pred, 2) / np.linalg.norm(S3_star, 2)\n",
    "    error_s4 = np.linalg.norm(S4_star - s4_pred, 2) / np.linalg.norm(S4_star, 2)\n",
    "    error_s5 = np.linalg.norm(S5_star - s5_pred, 2) / np.linalg.norm(S5_star, 2)\n",
    "    error_s6 = np.linalg.norm(S6_star - s6_pred, 2) / np.linalg.norm(S6_star, 2)\n",
    "\n",
    "\n",
    "    #Parameters\n",
    "    mu_m_value = model.sess.run(model.mu_m)\n",
    "    kd_m_value = model.sess.run(model.kd_m)\n",
    "    k1_value = model.sess.run(model.k1)\n",
    "    k2_value = model.sess.run(model.k2)\n",
    "    k3_value = model.sess.run(model.k3)\n",
    "    k4_value = model.sess.run(model.k4)\n",
    "    k5_value = model.sess.run(model.k5)\n",
    "    Y_xs1_value = model.sess.run(model.Y_xs1)\n",
    "    Y_xs2_value = model.sess.run(model.Y_xs2)\n",
    "    Y_xs3_value = model.sess.run(model.Y_xs3)\n",
    "    Y_xs5_value = model.sess.run(model.Y_xs5)\n",
    "    Y_xs6_value = model.sess.run(model.Y_xs6)\n",
    "    Y_s2s3_value = model.sess.run(model.Y_s2s3)\n",
    "    Y_s1s4_value = model.sess.run(model.Y_s1s4)\n",
    "    ms1_value = model.sess.run(model.ms1)\n",
    "\n",
    "\n",
    "    print('mu_m: %.8f, kd_m: %.8f, k1: %.8f, k2: %.8f, k3: %.8f, k4: %.8f, k5: %.8f, Y_xs1: %.8f, \\\n",
    "           Y_xs2: %.8f, Y_xs3: %.8f, Y_xs5: %.8f, Y_xs6:%.8f, Y_s2s3: %.8f, Y_s1s4: %.8f, ms1: %.8f' \\\n",
    "          % (mu_m_value, kd_m_value, k1_value, k2_value, k3_value, k4_value, k5_value, Y_xs1_value, \\\n",
    "             Y_xs2_value, Y_xs3_value, Y_xs5_value, Y_xs6_value, Y_s2s3_value, Y_s1s4_value, ms1_value))\n",
    "\n",
    "    print('Error x: %e' % (error_x))\n",
    "    print('Error s1: %e' % (error_s1))\n",
    "    print('Error s2: %e' % (error_s2))\n",
    "    print('Error s3: %e' % (error_s3))\n",
    "    print('Error s4: %e' % (error_s4))\n",
    "    print('Error s4: %e' % (error_s5))\n",
    "    print('Error s4: %e' % (error_s6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
